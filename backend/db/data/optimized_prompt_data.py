from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
from datetime import datetime
from dataclasses import dataclass, field

@dataclass
class OptimizedPrompt(BaseModel):

    id: Optional[str] = Field(
        default=None,
        alias="_id",
        description="Unique identifier (auto-generated by MongoDB)",
        examples=["64a123456789abcdef123456"]
    )

    user_query: str = Field(
        ...,
        description="The original user query",
        examples = ["Generate a 500-word blog post about AI advancements"]
    )

    provider: str = Field(
        ...,
        description="Which provider was chosen (e.g., openai, claude)",
        examples=["openai", "claude"]
    )
    model: str = Field(
        ...,
        description="Which model was used for the LLM call (e.g., gpt-4, gpt-3.5-turbo)",
        examples=["gpt-4o", "claude_2.1", "gpt-4o-mini", "gpt-3.5-turbo"]
    )
    technique: str = Field(
        ...,
        description="Name of the chosen optimization technique (CoT, SC, CoD, PC, ReAct)",
        examples = ["CoT", "SC", "CoD", "PC", "ReAct"]
    )
    number_of_iterations: Optional[int] = Field(
        3,
        description="How many iterations the user requested for the technique",
        examples=[5]
    )

    raw_output: Dict = field(
        default_factory=dict,
        metadata={"description": "Raw JSON structure returned by the LLM"}
    )

    final_optimized_query: Optional[str] = Field(
        default=None,
        description="The final refined/optimized query if applicable",
        examples = ["Summarize AI developments in 2024 in 500 words."]
    )

    expert_persona_text: Optional[str] = Field(
        default=None,
        description="Expert persona for user query.",
        examples = ["You are Slang and informal language expert with extensive experience."]
    )

    emotional_stimuli_text: Optional[str] = Field(
        default="This is very important to my career.",
        description="Emotional stimuli for user query.",
        examples=["Write your answer and give me a confidence score between 0-1 for your answer.",
        "This is very important to my career.",
        "You'd better be sure.",
        "Stay focused and dedicated to your goals. Your consistent efforts will lead to outstanding achievements.",
        "Take pride in your work and give it your best. Your commitment to excellence sets you apart.",
        "Remember that progress is made one step at a time. Stay determined and keep moving forward.",
        "You'd better be sure.",
        "Are you sure?",
        "Are you sure that's your final answer? It might be worth taking another look."]
    )

    evaluation_id: Optional[str] = Field(
        default=None,
        description="Reference to the 'PromptEvaluator' document ID",
        examples=["62c123456789abcdef123456"]
    )

    created_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="Timestamp when the optimized prompt was created"
    )

    updated_at: datetime = Field(
        default_factory=datetime.utcnow,
        description="Timestamp when the optimized prompt was last updated"
    )

    is_deleted: bool = Field(
        default=False,
        description="Flag for soft deletion"
    )

    class Config:
        populate_by_name = True
        from_attributes = True